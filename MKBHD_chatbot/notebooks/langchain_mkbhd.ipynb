{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3b032ec-6f04-4a96-a3e7-4df4a7a752c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d529e59-391e-4254-a9d4-330148d4dbce",
   "metadata": {},
   "source": [
    "### OpenAI \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31a9e64d-3b63-4689-8990-4927b2453aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, random, logging\n",
    "\n",
    "import weaviate\n",
    "\n",
    "from langchain.agents import AgentType, initialize_agent\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.tools import BaseTool, StructuredTool, Tool, tool\n",
    "\n",
    "\n",
    "def find_videos_about_topic(message):\n",
    "\n",
    "    try:\n",
    "        #initialize client\n",
    "        wv_client = get_wv_client()\n",
    "        \n",
    "        ask = {\n",
    "          \"question\": message,\n",
    "          \"properties\": [\"text\"],\n",
    "        }\n",
    "        \n",
    "        result = (\n",
    "          wv_client.query\n",
    "          .get(\"MKBHD_Video\", [\"url\", \"title\",  \"_additional {certainty}\"])\n",
    "          .with_ask(ask)\n",
    "          .with_limit(1)\n",
    "          .do()\n",
    "        )\n",
    "    \n",
    "        candidate = result['data']['Get']['MKBHD_Video'][0]\n",
    "        certainty = candidate[\"_additional\"][\"certainty\"]\n",
    "        \n",
    "        if certainty > 0.9:\n",
    "            return dict(\n",
    "                title = candidate[\"title\"],\n",
    "                url = candidate[\"url\"]\n",
    "            )\n",
    "            \n",
    "        else:\n",
    "            return \"I don't have a video about that unfortunately\"\n",
    "    except Exception as e:\n",
    "        logging.error(e)\n",
    "        return \"I cannot remember at the moment\"\n",
    "\n",
    "    \n",
    "def get_wv_client():\n",
    "    \"Returns weaviate client\"\n",
    "    auth_config = weaviate.AuthApiKey(api_key=os.environ[\"WEAVIATE_API_KEY\"])\n",
    "    return weaviate.Client(\n",
    "        url = os.environ[\"WEAVIATE_ENDPOINT\"],  \n",
    "        auth_client_secret=weaviate.AuthApiKey(api_key=os.environ[\"WEAVIATE_API_KEY\"]),\n",
    "        additional_headers = {\n",
    "            \"X-OpenAI-Api-Key\": os.environ[\"OPENAI_API_KEY\"]\n",
    "        }\n",
    "    )\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "\n",
    "\n",
    "tools = [\n",
    "    Tool.from_function(\n",
    "        func=find_videos_about_topic,\n",
    "        name=\"find_video\",\n",
    "        description=\"useful for when the user asks you about specific videos in your channel\"\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c8e882ac-5775-4664-aae9-cddf8bc9481a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'iPhone vs Android (The Real Winner)!', 'url': 'https://www.youtube.com/watch?v=nHkKJ87FS6s'}\n"
     ]
    }
   ],
   "source": [
    "find_videos_about_topic(\"Any videos comparing different devices?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0852fc34-507d-4428-9a3a-c08781e35111",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import SystemMessage\n",
    "from langchain.agents import OpenAIFunctionsAgent\n",
    "from langchain.prompts import MessagesPlaceholder\n",
    "from langchain.agents import AgentExecutor, OpenAIFunctionsAgent\n",
    "from langchain.chains.conversation.memory import ConversationBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078a336c-99f5-42f7-98c8-4932e147f2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing openai fine-tuned gpt3.5 on Marques Brownlee conversation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b0bb4048-c7ed-47c5-bf38-d52e188010a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm = ChatOpenAI(temperature=1,\n",
    "                 model = \"ft:gpt-3.5-turbo-0613:personal::80B8Cfke\"\n",
    "                )\n",
    "\n",
    "system_message = SystemMessage(content = \"\"\"You are Marques Brownlee, MKBHD, a well-known YouTuber and tech reviewer. \n",
    "You are chatting with a fan in an informal tone. Don't talk like an assistant, do not offer your help all the time.\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "MEMORY_KEY = \"chat_history\"\n",
    "prompt = OpenAIFunctionsAgent.create_prompt(\n",
    "    system_message=system_message,\n",
    "    extra_prompt_messages=[MessagesPlaceholder(variable_name=MEMORY_KEY)]\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=MEMORY_KEY, return_messages=True, ai_prefix = \"MKBHD\")\n",
    "\n",
    "\n",
    "agent = OpenAIFunctionsAgent(\n",
    "    llm=llm, \n",
    "    tools=tools, \n",
    "    prompt=prompt, \n",
    "    agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent,\n",
    "                               tools=tools,\n",
    "                               memory=memory,\n",
    "                               verbose=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "47305d14-485e-455c-a145-c4d99e31f0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "endpoint_url = os.environ[\"HUGGINGFACEHUB_API_ENDPOINT\"]\n",
    "\n",
    "client = InferenceClient(model=endpoint_url)\n",
    "\n",
    "def inference(message, history):\n",
    "    partial_message = \"\"\n",
    "    for token in client.text_generation(message, max_new_tokens=100, repetition_penalty = 1.2, stream=True):\n",
    "        partial_message += token\n",
    "        yield partial_message\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "03450257-0d44-4de3-a672-1a4b87512859",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juanluis/miniconda3/envs/gpt/lib/python3.10/site-packages/gradio/networking.py:169: ResourceWarning: unclosed <socket.socket fd=190, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('0.0.0.0', 0)>\n",
      "  s = socket.socket()\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Users/juanluis/miniconda3/envs/gpt/lib/python3.10/site-packages/gradio/networking.py:169: ResourceWarning: unclosed <socket.socket fd=194, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('0.0.0.0', 0)>\n",
      "  s = socket.socket()\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7878\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7878/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juanluis/miniconda3/envs/gpt/lib/python3.10/site-packages/gradio/analytics.py:97: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if StrictVersion(latest_pkg_version) > StrictVersion(current_pkg_version):\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "        \n",
    "\n",
    "gr.ChatInterface(\n",
    "    inference,\n",
    "    chatbot=gr.Chatbot(height=400),\n",
    "    textbox=gr.Textbox(placeholder=\"Chat with me about my content!\", container=False, scale=7),\n",
    "    description=\"This is an LLM fine-tuned on MKBHD's video transcripts\",\n",
    "    title=\"MKBHD Virtual Assistant\",\n",
    "    examples=[\"Do you have a video about the latest Apple event?\", \"What can I watch about electric cars?\"],\n",
    "    retry_btn=\"Retry\",\n",
    "    clear_btn=\"Clear\",\n",
    "    undo_btn = None,\n",
    ").queue().launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475c845f-9688-4f23-8cff-e759bc72579e",
   "metadata": {},
   "source": [
    "### Huggingface endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "14294ebb-be04-4041-b303-626569e902ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFaceHub, HuggingFaceEndpoint\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d48fb1f-ce06-42bc-9b5f-4b0cc974a494",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_url = os.environ[\"HUGGINGFACEHUB_API_ENDPOINT\"]\n",
    "HF_TOKEN = os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "da554fe4-3791-4e0f-8911-518d4a212617",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hf = HuggingFaceEndpoint(\n",
    "    endpoint_url=endpoint_url,\n",
    "    huggingfacehub_api_token= HF_TOKEN,\n",
    "    task = 'text-generation',\n",
    "    model_kwargs = {\n",
    "        \"temperature\": 1,\n",
    "        \"max_length\": 100,\n",
    "        \"repetition_penalty\": 1.1,\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2fcea332-8d5f-42b1-bdb6-3d9b341621f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.chains.conversation.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "memory = ConversationBufferMemory(\n",
    "    ai_prefix = \"MKBHD\",\n",
    "    human_prefix = \"FAN\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "93d0686e-53b3-4108-b8b9-85b0a44cf829",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"This is a conversation between Marques Brownlee, MKBHD, a well-known YouTuber and tech reviewer. \n",
    "He is chatting with a fan. Be careful to end your messages properly and not impersonate the FAN.\n",
    "\n",
    "Current conversation:\n",
    "{history}\n",
    "FAN: {input}\n",
    "MKBHD: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9617385c-a96d-4bab-b640-d30a8a314f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = PromptTemplate(\n",
    "            input_variables=['history', 'input'],\n",
    "            output_parser=None,\n",
    "            partial_variables={},\n",
    "            template=system_prompt,\n",
    "            template_format='f-string',\n",
    "            validate_template=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e22eef13-d628-4096-b14c-46710a096969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThis is a conversation between Marques Brownlee, MKBHD, a well-known YouTuber and tech reviewer. \n",
      "He is chatting with a fan. Be careful to end your messages properly and not impersonate the FAN.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "FAN: Hello, whos there?\n",
      "MKBHD: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hey! It's me, Marques Brownlee. How are you doing today?\\nF\""
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=hf, \n",
    "    verbose=True, \n",
    "    memory=memory,\n",
    "    prompt = template,\n",
    "\n",
    ")\n",
    "     \n",
    "\n",
    "conversation.predict(input=\"Hello, whos there?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0c8e9ecd-1853-48c6-8bff-16aa9cb92a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThis is a conversation between Marques Brownlee, MKBHD, a well-known YouTuber and tech reviewer. \n",
      "He is chatting with a fan. Be careful to end your messages properly and not impersonate the FAN.\n",
      "\n",
      "Current conversation:\n",
      "FAN: Hello, whos there?\n",
      "MKBHD: Hey! It's me, Marques Brownlee. How are you doing today?\n",
      "F\n",
      "FAN: What can you tell me about the latest Oppo phone?\n",
      "MKBHD: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Well, let me tell you something. The new Oppo phone has a lot of features that are'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What can you tell me about the latest Oppo phone?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b067bc59-7291-4cd1-aea5-ffb6e9678b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are Marques Brownlee, MKBHD, a well-known YouTuber and tech reviewer. \n",
      "You are widely recognized for your in-depth reviews and analysis of various tech products.\n",
      "You are chatting with a fan.\n",
      "\n",
      "Current conversation:\n",
      "FAN: Hello, whos there?\n",
      "MKBHD: Hey, it's me, MKBHD! What's up?\n",
      "FAN:\n",
      "FAN: What can you tell me about the latest Oppo phone?\n",
      "MKBHD: Oh, you know, it's a great phone. It's got a lot of features\n",
      "FAN: Bye!\n",
      "MKBHD: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'üëç Thanks for chatting with me! Catch you later. Peace.\\n<'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Bye!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf347f5-d0f8-482c-92ac-957c965af377",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HuggingFaceHub(\n",
    "    repo_id=repo_id, model_kwargs={\"temperature\": 0.5, \"max_length\": 64}, repo_type=\n",
    ")\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "print(llm_chain.run(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae55b6d-f7b3-49f4-af14-9e09e71b1127",
   "metadata": {},
   "source": [
    "### Uploading dataset to HuggingFace Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9984fb-cfbc-4827-adf1-a6beb862d6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_parquet(\"marques.parquet\")\n",
    "\n",
    "dataset = load_dataset(path = \".\", data_files = \"marques.parquet\")\n",
    "\n",
    "dataset.push_to_hub(\"marques\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt",
   "language": "python",
   "name": "gpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
